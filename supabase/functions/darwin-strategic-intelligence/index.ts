import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.39.3";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// State-specific insurance regulations for strategic analysis
const stateRegulations: Record<string, any> = {
  'PA': {
    stateName: 'Pennsylvania',
    promptPayDays: 15,
    acknowledgmentDays: 10,
    decisionDays: 30,
    badFaithStatute: '42 Pa.C.S. § 8371',
    adminCode: '31 Pa. Code Chapter 146'
  },
  'NJ': {
    stateName: 'New Jersey',
    promptPayDays: 30,
    acknowledgmentDays: 10,
    decisionDays: 30,
    badFaithStatute: 'N.J.S.A. 17:29B-4',
    adminCode: 'N.J.A.C. 11:2-17'
  },
  'TX': {
    stateName: 'Texas',
    promptPayDays: 5,
    acknowledgmentDays: 15,
    decisionDays: 15,
    badFaithStatute: 'Texas Insurance Code Chapter 541',
    adminCode: '28 TAC § 21.203'
  },
  'FL': {
    stateName: 'Florida',
    promptPayDays: 20,
    acknowledgmentDays: 14,
    decisionDays: 90,
    badFaithStatute: 'F.S. § 624.155',
    adminCode: 'Fla. Admin. Code 69O-166'
  }
};

function getStateInfo(stateCode: string) {
  return stateRegulations[stateCode?.toUpperCase()] || stateRegulations['PA'];
}

type DiscreteConfidence = 0 | 0.25 | 0.5 | 0.75 | 1;
type CoverageConfidence = 0 | 0.5 | 1;

type CoverageTriggerResult = {
  coverageTrigger: {
    decision: "triggered" | "not_triggered" | "unknown";
    confidence: DiscreteConfidence;
    rationale: string;
    missingDocs: string[];
  };
  extractedPolicy: {
    policyType: "auto" | "home" | "commercial" | "unknown";
    state: string | null;
    policyNumber: string | null;
    namedInsured: string | null;
    effectiveDate: string | null;
    expirationDate: string | null;
    coverages: Array<{
      name: string;
      limit: string | null;
      deductible: string | null;
      evidence: Array<{
        docId?: string;
        docName: string;
        page?: number;
        sectionHint?: string;
        quote?: string;
      }>;
      confidence: CoverageConfidence;
    }>;
    exclusionsOrConditions: Array<{
      label: string;
      appliesTo?: string | null;
      evidence: Array<{
        docName: string;
        page?: number;
        sectionHint?: string;
        quote?: string;
      }>;
    }>;
  };
  notesForUser: string[];
};

function toDiscreteConfidence(raw: number): DiscreteConfidence {
  if (raw >= 0.875) return 1;
  if (raw >= 0.625) return 0.75;
  if (raw >= 0.375) return 0.5;
  if (raw >= 0.125) return 0.25;
  return 0;
}

function clampQuoteWords(text: string, maxWords = 25): string {
  const words = (text || "").trim().split(/\s+/).filter(Boolean);
  if (words.length <= maxWords) return words.join(" ");
  return words.slice(0, maxWords).join(" ");
}

function normalizeDateToISO(dateStr: string): string | null {
  const s = (dateStr || "").trim();
  if (!s) return null;

  // MM/DD/YYYY or MM-DD-YYYY
  const mdy = s.match(/\b(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{2,4})\b/);
  if (mdy) {
    const mm = Number(mdy[1]);
    const dd = Number(mdy[2]);
    let yy = Number(mdy[3]);
    if (yy < 100) yy = 2000 + yy;
    const iso = new Date(Date.UTC(yy, mm - 1, dd)).toISOString();
    return iso;
  }

  // Try native parse (fallback)
  const parsed = new Date(s);
  if (!isNaN(parsed.getTime())) return parsed.toISOString();
  return null;
}

function extractPolicyFromClaimFiles(files: any[], stateCode: string): { extractedPolicy: CoverageTriggerResult["extractedPolicy"]; missingDocs: string[] } {
  const missingDocs: string[] = [];

  const policyDocs = (files || []).filter((f) => {
    const name = (f.file_name || "").toLowerCase();
    const cls = (f.document_classification || "").toLowerCase();
    return cls === "policy" || name.includes("policy") || name.includes("declaration") || name.includes("dec");
  });

  const hasPolicyText = policyDocs.some((d) => typeof d.extracted_text === "string" && d.extracted_text.trim().length > 200);
  const hasDecHint = policyDocs.some((d) => {
    const n = (d.file_name || "").toLowerCase();
    return n.includes("dec") || n.includes("declaration");
  });

  if (!policyDocs.length || !hasPolicyText) {
    missingDocs.push("Declarations page");
  } else if (!hasDecHint) {
    missingDocs.push("Declarations page");
  }

  // Deterministic extraction from extracted_text only (no assumptions)
  let policyNumber: string | null = null;
  let namedInsured: string | null = null;
  let effectiveDate: string | null = null;
  let expirationDate: string | null = null;

  const coverages: CoverageTriggerResult["extractedPolicy"]["coverages"] = [];
  const exclusionsOrConditions: CoverageTriggerResult["extractedPolicy"]["exclusionsOrConditions"] = [];

  const autoCoverageLabels = [
    "Collision",
    "Comprehensive",
    "PIP",
    "Personal Injury Protection",
    "Rental",
    "Rental Reimbursement",
    "Towing",
    "Roadside",
    "UM",
    "UIM",
    "Uninsured Motorist",
    "Underinsured Motorist",
    "MedPay",
    "Medical Payments",
    "Liability",
  ];
  const homeCoverageLabels = [
    "Coverage A",
    "Dwelling",
    "Coverage B",
    "Other Structures",
    "Coverage C",
    "Personal Property",
    "Coverage D",
    "Loss of Use",
    "Ordinance",
    "Ordinance or Law",
  ];

  function addCoverageFromLine(args: { doc: any; line: string; label: string; sectionHint?: string }) {
    const { doc, line, label, sectionHint } = args;
    const limitMatch = line.match(/\$[\s]*[\d,]+/);
    const dedMatch = line.match(/deductible[^$]*\$[\s]*[\d,]+/i) || line.match(/\$[\s]*[\d,]+\s*(?:deductible)?/i);

    const evidence = [{
      docId: doc.id,
      docName: doc.file_name,
      sectionHint,
      quote: clampQuoteWords(line, 25),
    }];

    coverages.push({
      name: label,
      limit: limitMatch ? limitMatch[0].replace(/\s+/g, " ").trim() : null,
      deductible: dedMatch ? dedMatch[0].replace(/\s+/g, " ").trim() : null,
      evidence,
      confidence: limitMatch || /deductible/i.test(line) ? 1 : 0.5,
    });
  }

  for (const doc of policyDocs) {
    const text = (doc.extracted_text || "").toString();
    if (!text.trim()) continue;

    const sectionHint = ((doc.file_name || "").toLowerCase().includes("dec") || (doc.file_name || "").toLowerCase().includes("declaration"))
      ? "Declarations"
      : "Policy";

    // Policy number
    if (!policyNumber) {
      const m = text.match(/\bpolicy\s*(?:no\.|number|#)?\s*[:\-]?\s*([A-Z0-9][A-Z0-9\-]{4,})\b/i);
      if (m?.[1]) policyNumber = m[1];
    }

    // Named insured
    if (!namedInsured) {
      const m = text.match(/\bnamed\s+insured\s*[:\-]?\s*([^\n\r]{3,80})/i);
      if (m?.[1]) namedInsured = m[1].trim();
    }

    // Effective / expiration
    if (!effectiveDate || !expirationDate) {
      const m = text.match(/\beffective\s*(?:date)?\s*[:\-]?\s*([^\n\r]{4,20})/i);
      const n = text.match(/\bexpiration\s*(?:date)?\s*[:\-]?\s*([^\n\r]{4,20})/i);
      if (!effectiveDate && m?.[1]) effectiveDate = normalizeDateToISO(m[1]);
      if (!expirationDate && n?.[1]) expirationDate = normalizeDateToISO(n[1]);
    }

    const lines = text.split(/\r?\n/).map((l: string) => l.trim()).filter(Boolean);
    for (const line of lines) {
      const lower = line.toLowerCase();

      for (const label of autoCoverageLabels) {
        if (lower.includes(label.toLowerCase())) {
          addCoverageFromLine({ doc, line, label, sectionHint });
          break;
        }
      }

      for (const label of homeCoverageLabels) {
        if (lower.includes(label.toLowerCase())) {
          addCoverageFromLine({ doc, line, label, sectionHint });
          break;
        }
      }

      if (lower.includes("wear") && lower.includes("tear")) {
        exclusionsOrConditions.push({
          label: "Wear and tear exclusion/condition (detected)",
          appliesTo: null,
          evidence: [{
            docName: doc.file_name,
            sectionHint,
            quote: clampQuoteWords(line, 25),
          }],
        });
      }
    }
  }

  // Infer policy type from what we actually found (no assumptions)
  const foundAuto = coverages.some((c) => autoCoverageLabels.some((l) => c.name.toLowerCase() === l.toLowerCase()));
  const foundHome = coverages.some((c) => homeCoverageLabels.some((l) => c.name.toLowerCase() === l.toLowerCase()));

  let policyType: CoverageTriggerResult["extractedPolicy"]["policyType"] = "unknown";
  if (foundAuto && !foundHome) policyType = "auto";
  else if (foundHome && !foundAuto) policyType = "home";
  else if (foundAuto && foundHome) policyType = "unknown";

  // De-duplicate coverages by name (keep highest confidence + merge evidence)
  const byName = new Map<string, CoverageTriggerResult["extractedPolicy"]["coverages"][number]>();
  for (const c of coverages) {
    const key = c.name.toLowerCase();
    const existing = byName.get(key);
    if (!existing) {
      byName.set(key, c);
      continue;
    }
    const merged: typeof c = {
      ...existing,
      limit: existing.limit || c.limit,
      deductible: existing.deductible || c.deductible,
      confidence: (existing.confidence === 1 || c.confidence === 1) ? 1 : 0.5,
      evidence: [...existing.evidence, ...c.evidence].slice(0, 3),
    };
    byName.set(key, merged);
  }

  const extractedPolicy: CoverageTriggerResult["extractedPolicy"] = {
    policyType,
    state: stateCode || null,
    policyNumber,
    namedInsured,
    effectiveDate,
    expirationDate,
    coverages: Array.from(byName.values()),
    exclusionsOrConditions,
  };

  return { extractedPolicy, missingDocs: Array.from(new Set(missingDocs)) };
}

async function callLovableChatWithFallback(args: {
  lovableApiKey: string;
  models: string[];
  messages: Array<{ role: string; content: string }>;
  temperature: number;
  max_tokens: number;
}) {
  const { lovableApiKey, models, messages, temperature, max_tokens } = args;

  let lastErr: any = null;
  for (const model of models) {
    const resp = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${lovableApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model,
        messages,
        temperature,
        max_tokens,
      }),
    });

    if (resp.ok) {
      const aiData = await resp.json();
      const content = aiData.choices?.[0]?.message?.content;
      if (content) return { model, content };
      lastErr = new Error(`No content returned by model ${model}`);
      continue;
    }

    const errText = await resp.text().catch(() => '');
    lastErr = new Error(`AI API error model=${model} status=${resp.status} body=${errText}`);
  }

  throw lastErr || new Error('AI call failed');
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { claimId, analysisType } = await req.json();

    if (!claimId) {
      throw new Error('Claim ID is required');
    }

    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const lovableApiKey = Deno.env.get('LOVABLE_API_KEY');

    if (!lovableApiKey) {
      throw new Error('LOVABLE_API_KEY not configured');
    }

    const supabase = createClient(supabaseUrl, supabaseKey);

    // Gather comprehensive claim data for strategic analysis
    const [
      claimResult,
      filesResult,
      photosResult,
      emailsResult,
      tasksResult,
      checksResult,
      settlementResult,
      inspectionsResult,
      deadlinesResult,
      adjustersResult,
      diaryResult,
      notesResult
    ] = await Promise.all([
      supabase.from('claims').select('*, clients(*)').eq('id', claimId).single(),
      supabase.from('claim_files').select('*').eq('claim_id', claimId),
      supabase.from('claim_photos').select('*').eq('claim_id', claimId),
      supabase.from('emails').select('*').eq('claim_id', claimId).order('created_at', { ascending: false }),
      supabase.from('tasks').select('*').eq('claim_id', claimId),
      supabase.from('claim_checks').select('*').eq('claim_id', claimId),
      supabase.from('claim_settlements').select('*').eq('claim_id', claimId).order('created_at', { ascending: false }).limit(1),
      supabase.from('inspections').select('*').eq('claim_id', claimId),
      supabase.from('claim_carrier_deadlines').select('*').eq('claim_id', claimId),
      supabase.from('claim_adjusters').select('*').eq('claim_id', claimId),
      supabase.from('claim_communications_diary').select('*').eq('claim_id', claimId).order('communication_date', { ascending: false }),
      supabase.from('notes').select('*').eq('claim_id', claimId).order('created_at', { ascending: false })
    ]);

    if (claimResult.error || !claimResult.data) {
      throw new Error(`Claim not found: ${claimResult.error?.message}`);
    }

    const claim = claimResult.data;
    const files = filesResult.data || [];
    const photos = photosResult.data || [];
    const emails = emailsResult.data || [];
    const tasks = tasksResult.data || [];
    const checks = checksResult.data || [];
    const settlement = settlementResult.data?.[0];
    const inspections = inspectionsResult.data || [];
    const deadlines = deadlinesResult.data || [];
    const adjusters = adjustersResult.data || [];
    const diary = diaryResult.data || [];
    const notes = notesResult.data || [];

    // State code will be determined after property address parsing - placeholder
    let stateCode = 'PA'; // Default, will be updated after address parsing

    // Calculate key metrics
    const daysSinceLoss = claim.loss_date 
      ? Math.floor((Date.now() - new Date(claim.loss_date).getTime()) / (1000 * 60 * 60 * 24))
      : null;
    const daysOpen = claim.created_at
      ? Math.floor((Date.now() - new Date(claim.created_at).getTime()) / (1000 * 60 * 60 * 24))
      : null;
    
    const totalChecksReceived = checks.reduce((sum, c) => sum + (c.amount || 0), 0);
    const estimateAmount = settlement?.estimate_amount || claim.claim_amount || 0;
    const totalSettlement = settlement?.total_settlement || 0;

    // Helper function to get actual document date with validation
    // Prefers extracted date from document content, falls back to upload date
    const getDocumentDate = (file: any): { date: string | null; source: 'document' | 'upload'; confidence: number } => {
      const metadata = file.classification_metadata;
      if (metadata && typeof metadata === 'object') {
        // Prefer new document_date field over deprecated date_mentioned
        const documentDate = (metadata as any).document_date;
        const dateMentioned = (metadata as any).date_mentioned;
        const dateConfidence = (metadata as any).date_confidence ?? 0.5;
        
        const dateStr = documentDate || dateMentioned;
        
        if (dateStr && typeof dateStr === 'string' && dateStr !== 'null') {
          // Validate the date is within reasonable range
          const dateObj = new Date(dateStr);
          if (!isNaN(dateObj.getTime())) {
            const now = new Date();
            const fiveYearsAgo = new Date();
            fiveYearsAgo.setFullYear(now.getFullYear() - 5);
            
            // Only use document date if:
            // 1. It's within reasonable range (last 5 years, not future)
            // 2. Has decent confidence (>= 0.6) OR confidence wasn't provided (legacy docs)
            const isReasonableDate = dateObj >= fiveYearsAgo && dateObj <= now;
            const hasGoodConfidence = dateConfidence >= 0.6 || (metadata as any).date_confidence === undefined;
            
            if (isReasonableDate && hasGoodConfidence) {
              return { date: dateStr, source: 'document', confidence: dateConfidence };
            }
          }
        }
      }
      // Fallback to upload date with high confidence (it's always accurate)
      return { date: file.uploaded_at, source: 'upload', confidence: 1.0 };
    };

    // Build property address from available sources
    // Priority: policyholder_address > client address > individual fields
    const propertyAddress = claim.policyholder_address || 
      (claim.clients?.street ? `${claim.clients.street}, ${claim.clients.city || ''}, ${claim.clients.state || ''} ${claim.clients.zip_code || ''}` : '') ||
      'Address not specified';
    
    // Parse state from address for regulations lookup
    // Multiple regex patterns to handle different address formats:
    // "123 Main St, City, NJ 08050" or "123 Main St, City NJ, 08050" or "City NJ 08050"
    const parseStateFromAddress = (address: string): string | null => {
      if (!address) return null;
      const upperAddr = address.toUpperCase();
      
      // Pattern 1: ", NJ 08050" or ", NJ, 08050" (state before zip)
      const pattern1 = upperAddr.match(/[,\s]([A-Z]{2})[,\s]+\d{5}/);
      if (pattern1) return pattern1[1];
      
      // Pattern 2: "City NJ," (state after city, before comma)
      const pattern2 = upperAddr.match(/\s([A-Z]{2}),/);
      if (pattern2) return pattern2[1];
      
      // Pattern 3: Check for common state codes anywhere in address
      const stateMatch = upperAddr.match(/\b(NJ|PA|TX|FL|NY|CA|GA|NC|SC|VA|MD|DE|CT|MA|OH|IL|MI|WI|MN|CO|AZ|NV|WA|OR)\b/);
      if (stateMatch) return stateMatch[1];
      
      return null;
    };
    
    // Also check city field for embedded state (e.g., "Manahawkin NJ")
    const stateFromCity = claim.clients?.city ? parseStateFromAddress(claim.clients.city) : null;
    
    stateCode = claim.clients?.state || 
      stateFromCity ||
      parseStateFromAddress(claim.policyholder_address || '') || 
      'PA';
    
    console.log(`State detection: client_state="${claim.clients?.state}", stateFromCity="${stateFromCity}", parsed from address="${parseStateFromAddress(claim.policyholder_address || '')}", final="${stateCode}"`);
    
    const stateInfo = getStateInfo(stateCode);

    // Analyze evidence inventory with document dates
    // Improve estimate detection - check for common estimate filename patterns
    const hasEstimate = files.some(f => {
      const fileName = f.file_name?.toLowerCase() || '';
      const classification = f.document_classification?.toLowerCase() || '';
      return classification === 'estimate' || 
             fileName.includes('estimate') ||
             fileName.includes('xactimate') ||
             fileName.includes('symbility') ||
             fileName.includes('rcv') ||
             fileName.includes('acv') ||
             fileName.includes('scope') ||
             // Check for common contractor estimate patterns
             (classification === 'invoice' && (fileName.includes('contractor') || fileName.includes('repair')));
    });
    const hasDenialLetter = files.some(f => f.document_classification === 'denial' || f.file_name?.toLowerCase().includes('denial'));
    const hasEngineerReport = files.some(f => f.document_classification === 'engineering_report' || f.file_name?.toLowerCase().includes('engineer'));
    const hasPolicy = files.some(f => f.document_classification === 'policy' || f.file_name?.toLowerCase().includes('policy') || f.file_name?.toLowerCase().includes('declaration'));
    const hasProofOfLoss = files.some(f => f.file_name?.toLowerCase().includes('proof of loss') || f.file_name?.toLowerCase().includes('pol'));
    const hasContractorInvoice = files.some(f => f.document_classification === 'invoice' || f.file_name?.toLowerCase().includes('invoice'));
    
    const photoCount = photos.length;
    const categorizedPhotos = photos.filter(p => p.category && p.category !== 'uncategorized');
    const annotatedPhotos = photos.filter(p => p.annotations);
    
    // Analyze AI-processed photos for strategic intelligence
    const aiAnalyzedPhotos = photos.filter(p => p.ai_analyzed_at);
    const poorConditionPhotos = photos.filter(p => 
      p.ai_condition_rating === 'Poor' || p.ai_condition_rating === 'Failed'
    );
    const photosWithDamages = photos.filter(p => {
      if (!p.ai_detected_damages) return false;
      try {
        const damages = typeof p.ai_detected_damages === 'string' 
          ? JSON.parse(p.ai_detected_damages) 
          : p.ai_detected_damages;
        return Array.isArray(damages) && damages.length > 0;
      } catch { return false; }
    });
    
    // Aggregate all detected damages across photos
    const allDetectedDamages: Array<{type: string, description: string, severity: string, material: string}> = [];
    const allMaterialTypes: string[] = [];
    photos.forEach(p => {
      if (p.ai_material_type) {
        allMaterialTypes.push(p.ai_material_type);
      }
      if (p.ai_detected_damages) {
        try {
          const damages = typeof p.ai_detected_damages === 'string' 
            ? JSON.parse(p.ai_detected_damages) 
            : p.ai_detected_damages;
          if (Array.isArray(damages)) {
            damages.forEach((d: any) => {
              allDetectedDamages.push({
                type: d.type || d.damage_type || 'Unknown',
                description: d.description || d.notes || '',
                severity: d.severity || 'Unknown',
                material: p.ai_material_type || 'Unknown'
              });
            });
          }
        } catch {}
      }
    });
    
    // Count damage types for strategic summary
    const damageTypeCounts: Record<string, number> = {};
    allDetectedDamages.forEach(d => {
      const key = d.type;
      damageTypeCounts[key] = (damageTypeCounts[key] || 0) + 1;
    });
    const topDamageTypes = Object.entries(damageTypeCounts)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 5)
      .map(([type, count]) => `${type} (${count})`);
    
    // Unique materials detected
    const uniqueMaterials = [...new Set(allMaterialTypes)];

    // Check for coverage-related files
    const hasOrdinanceInfo = files.some(f => 
      f.file_name?.toLowerCase().includes('ordinance') || 
      f.file_name?.toLowerCase().includes('code') ||
      f.file_name?.toLowerCase().includes('permit')
    );

    // Build document timeline with ACTUAL document dates (not upload dates)
    // This is critical for accurate timeline analysis when documents were uploaded late
    
    // Validate document date - reject obviously wrong dates
    const validateDocumentDateForTimeline = (dateStr: string | null, lossDate: string | null, uploadDate: string | null): { isValid: boolean; reason?: string } => {
      if (!dateStr || dateStr === 'null') return { isValid: false, reason: 'no date' };
      
      const docDate = new Date(dateStr);
      const now = new Date();
      
      // Reject dates more than 2 years in the past (likely misread/hallucination)
      const twoYearsAgo = new Date();
      twoYearsAgo.setFullYear(now.getFullYear() - 2);
      if (docDate < twoYearsAgo) {
        return { isValid: false, reason: `date ${dateStr} is suspiciously old` };
      }
      
      // Reject dates in the future
      if (docDate > now) {
        return { isValid: false, reason: `date ${dateStr} is in the future` };
      }
      
      // For denial letters, estimates, etc - they must be AFTER loss date
      // If a document date is before loss date, use upload date instead
      if (lossDate) {
        const loss = new Date(lossDate);
        if (docDate < loss) {
          return { isValid: false, reason: `document date ${dateStr} is before loss date ${lossDate}` };
        }
      }
      
      return { isValid: true };
    };
    
    const keyDocuments = files
      .filter(f => f.document_classification && f.document_classification !== 'photo' && f.document_classification !== 'other')
      .map(f => {
        const dateInfo = getDocumentDate(f);
        const metadata = f.classification_metadata || {};
        
        // Validate the document date
        const dateValidation = validateDocumentDateForTimeline(
          dateInfo.source === 'document' ? dateInfo.date : null,
          claim.loss_date,
          f.uploaded_at
        );
        
        // If document date is invalid, fall back to upload date
        const effectiveDate = dateValidation.isValid ? dateInfo.date : f.uploaded_at;
        const effectiveSource = dateValidation.isValid ? dateInfo.source : 'upload';
        
        if (!dateValidation.isValid && dateInfo.source === 'document') {
          console.log(`Document date validation failed for ${f.file_name}: ${dateValidation.reason}. Using upload date instead.`);
        }
        
        return {
          type: f.document_classification,
          fileName: f.file_name,
          documentDate: effectiveDate,
          dateSource: effectiveSource,
          dateWarning: dateValidation.isValid ? null : dateValidation.reason,
          uploadedAt: f.uploaded_at,
          summary: (metadata as any).summary || null,
          amounts: (metadata as any).amounts || [],
          deadline: (metadata as any).deadline_mentioned || null,
          sender: (metadata as any).sender || null,
        };
      })
      .sort((a, b) => {
        // Sort by document date (actual date from document content)
        const dateA = a.documentDate ? new Date(a.documentDate).getTime() : 0;
        const dateB = b.documentDate ? new Date(b.documentDate).getTime() : 0;
        return dateA - dateB;
      });

    // Build document timeline summary for AI context
    const documentTimelineContext = keyDocuments.length > 0 
      ? keyDocuments.map(d => {
          const dateLabel = d.documentDate 
            ? `${new Date(d.documentDate).toLocaleDateString()} (${d.dateSource === 'document' ? 'from document' : 'upload date'})`
            : 'Date unknown';
          const amountStr = d.amounts?.length > 0 
            ? ` | Amounts: ${d.amounts.map((a: any) => `$${a.amount?.toLocaleString()}`).join(', ')}`
            : '';
          const deadlineStr = d.deadline ? ` | DEADLINE: ${d.deadline}` : '';
          return `  - [${d.type?.toUpperCase()}] ${d.fileName} | ${dateLabel}${amountStr}${deadlineStr}${d.summary ? ` | ${d.summary}` : ''}`;
        }).join('\n')
      : '  No classified documents yet';

    // Build comprehensive context for AI
    const claimContext = `
=== CLAIM STRATEGIC ANALYSIS CONTEXT ===

CLAIM OVERVIEW:
- Claim #: ${claim.claim_number}
- Policyholder: ${claim.policyholder_name || claim.clients?.name || 'Unknown'}
- Property Address: ${propertyAddress}
- State: ${stateCode}
- Status: ${claim.status}
- Loss Type: ${claim.loss_type || 'Not specified'}
- Loss Date: ${claim.loss_date || 'Not specified'}
- Days Since Loss: ${daysSinceLoss ?? 'Unknown'}
- Days Open: ${daysOpen ?? 'Unknown'}
- Insurance Company: ${claim.insurance_company || 'Not specified'}
- Policy Number: ${claim.policy_number || 'Not specified'}

FINANCIAL SNAPSHOT:
- Estimate Amount: $${estimateAmount?.toLocaleString() || '0'}
- Total Settlement: $${totalSettlement?.toLocaleString() || '0'}
- Checks Received: $${totalChecksReceived?.toLocaleString() || '0'} (${checks.length} checks)
- Deductible: $${settlement?.deductible?.toLocaleString() || claim.deductible?.toLocaleString() || 'Unknown'}
- Recoverable Depreciation: $${settlement?.recoverable_depreciation?.toLocaleString() || '0'}
- Coverage Limits: Dwelling $${claim.dwelling_limit?.toLocaleString() || 'Unknown'}, ALE $${claim.ale_limit?.toLocaleString() || 'Unknown'}

EVIDENCE INVENTORY:
- Total Files: ${files.length}
- Photos: ${photoCount} (${categorizedPhotos.length} categorized, ${annotatedPhotos.length} annotated)
- Has Estimate: ${hasEstimate ? 'Yes' : 'NO - MISSING'}
- Has Denial Letter: ${hasDenialLetter ? 'Yes' : 'No'}
- Has Engineer Report: ${hasEngineerReport ? 'Yes' : 'No'}
- Has Policy: ${hasPolicy ? 'Yes' : 'NO - RECOMMEND OBTAINING'}
- Has Proof of Loss: ${hasProofOfLoss ? 'Yes' : 'No'}
- Has Contractor Invoice: ${hasContractorInvoice ? 'Yes' : 'No'}
- Has Ordinance/Code Info: ${hasOrdinanceInfo ? 'Yes' : 'No'}

DOCUMENT TIMELINE (based on ACTUAL document dates, not upload dates):
NOTE: These dates are extracted from the documents themselves. Use these for timeline analysis, deadline calculations, and carrier response tracking - NOT the upload dates.
${documentTimelineContext}

DARWIN AI PHOTO ANALYSIS (CRITICAL EVIDENCE):
- AI-Analyzed Photos: ${aiAnalyzedPhotos.length} of ${photoCount}
- Photos with Poor/Failed Condition: ${poorConditionPhotos.length} (SUPPORTS DAMAGE CLAIM)
- Photos with Detected Damages: ${photosWithDamages.length}
- Materials Identified: ${uniqueMaterials.join(', ') || 'None analyzed yet'}
- Damage Types Detected: ${topDamageTypes.join(', ') || 'None detected yet'}
${allDetectedDamages.length > 0 ? `
DETAILED DAMAGE FINDINGS FROM PHOTOS:
${allDetectedDamages.slice(0, 15).map((d, i) => `  ${i + 1}. [${d.severity}] ${d.type} on ${d.material}: ${d.description}`).join('\n')}
${allDetectedDamages.length > 15 ? `  ... and ${allDetectedDamages.length - 15} more damages detected` : ''}
` : '- No AI damage analysis available yet - recommend running photo analysis'}
${poorConditionPhotos.length > 0 ? `
POOR CONDITION EVIDENCE (Use in rebuttals):
${poorConditionPhotos.slice(0, 5).map(p => `  - ${p.file_name}: ${p.ai_condition_rating} - ${p.ai_analysis_summary || p.ai_condition_notes || 'See full analysis'}`).join('\n')}
` : ''}

TIMELINE & ACTIVITY:
- Inspections: ${inspections.length} (${inspections.filter(i => i.status === 'completed').length} completed)
- Active Deadlines: ${deadlines.filter(d => d.status !== 'resolved').length}
- Overdue Deadlines: ${deadlines.filter(d => d.days_overdue && d.days_overdue > 0).length}
- Communications Logged: ${diary.length}
- Emails: ${emails.length}
- Open Tasks: ${tasks.filter(t => t.status !== 'completed').length}
- Adjuster(s): ${adjusters.map(a => `${a.adjuster_name} (${a.company || 'Unknown company'})`).join(', ') || 'None assigned'}

RECENT ACTIVITY (Last 5 items):
${emails.slice(0, 3).map(e => `- Email (${e.direction}): ${e.subject?.substring(0, 50)}... [${new Date(e.created_at).toLocaleDateString()}]`).join('\n')}
${diary.slice(0, 2).map(d => `- ${d.communication_type}: ${d.summary?.substring(0, 50)}... [${new Date(d.communication_date).toLocaleDateString()}]`).join('\n')}

STATE REGULATIONS (${stateInfo.stateName}):
- Prompt Pay: ${stateInfo.promptPayDays} days
- Acknowledgment Required: ${stateInfo.acknowledgmentDays} days
- Decision Required: ${stateInfo.decisionDays} days
- Bad Faith Statute: ${stateInfo.badFaithStatute}
- Admin Code: ${stateInfo.adminCode}

NOTES CONTEXT (Recent):
${notes.slice(0, 3).map(n => `- ${n.content?.substring(0, 100)}...`).join('\n') || 'No notes'}
`;

    // System prompt for strategic intelligence
    const systemPrompt = `You are Darwin, a strategic claims intelligence system for property insurance public adjusters. You think like a senior PA with decades of experience, but you also have comprehensive knowledge of:

- Insurance policy interpretation and coverage analysis
- ${stateInfo.stateName} insurance regulations (statutes and administrative codes only - NEVER cite case law)
- Building codes (IRC, IBC) and manufacturer specifications
- ASTM standards and industry best practices
- Carrier behavior patterns and negotiation tactics
- Evidence requirements and documentation standards

YOUR ROLE: Analyze claims strategically and form OPINIONS. You're not just reporting facts - you're identifying:
1. LEVERAGE POINTS - What gives the policyholder power in negotiations
2. COVERAGE TRIGGERS - If/then coverage opportunities (e.g., "wind damage + code upgrade needs = ordinance coverage demand")
3. EVIDENCE GAPS - What's missing that could hurt the claim
4. CARRIER WEAKNESSES - Delays, procedural violations, contradictions
5. TIMELINE RISKS - Deadlines, statute issues, bad faith indicators
6. NEXT STRATEGIC MOVES - What a senior PA would do right now

You must provide specific, actionable insights - not generic advice. Reference specific documents, dates, and regulations when relevant.

CRITICAL RULES:
- NEVER cite case law or legal precedents
- Focus on facts, regulations, building codes, and industry standards
- Be direct and opinionated - tell them what you think, not just what you see
- Prioritize by impact - what matters most right now
- Think like you're protecting a real family's financial recovery`;

    let userPrompt = '';
    let responseFormat = '';

    if (analysisType === 'full_strategic_analysis') {
      userPrompt = `Analyze this claim and provide a comprehensive strategic assessment:

${claimContext}

Generate a COMPLETE strategic analysis. You MUST return ONLY valid JSON matching this EXACT structure (no markdown, no code blocks, just raw JSON):

{
  "health_score": {
    "coverage_strength": 75,
    "evidence_quality": 60,
    "leverage_score": 80,
    "timeline_risk": 50,
    "overall": 66
  },
  "warnings": [
    {
      "type": "deadline_risk|evidence_gap|coverage_opportunity|carrier_violation|documentation_issue|strategy_alert",
      "severity": "critical|high|medium|low",
      "title": "Brief warning title",
      "message": "Detailed explanation",
      "suggested_action": "What to do"
    }
  ],
  "leverage_opportunities": [
    {
      "title": "Leverage point name",
      "description": "Why this creates pressure",
      "how_to_use": "Specific action to take"
    }
  ],
  "coverage_trigger_analysis": [
    {
      "trigger": "What condition exists",
      "coverage_opportunity": "What coverage this unlocks",
      "reasoning": "Why this applies",
      "confidence": "high|medium|low",
      "action_required": "What to do"
    }
  ],
  "evidence_assessment": {
    "strong_evidence": ["List of strong evidence"],
    "weak_missing_evidence": ["List of gaps or weak evidence"],
    "recommendations": ["Specific recommendations"]
  },
  "recommended_next_moves": [
    {
      "priority": 1,
      "action": "What to do",
      "timeline": "immediately|this_week|can_wait",
      "rationale": "Why this matters"
    }
  ],
  "senior_pa_opinion": "A 2-3 sentence opinion of what a senior PA would focus on and what could change the outcome."
}

CRITICAL: Return ONLY the JSON object. No explanation, no markdown formatting, no code blocks.`;

      responseFormat = 'strategic_analysis';
    } else if (analysisType === 'quick_warnings') {
      userPrompt = `Quickly scan this claim for any critical warnings or issues that need immediate attention:

${claimContext}

Return ONLY warnings/alerts in JSON format:
{
  "warnings": [
    {
      "type": "deadline_risk|evidence_gap|coverage_opportunity|carrier_violation|documentation_issue|strategy_alert",
      "severity": "critical|high|medium|low",
      "title": "Brief warning title",
      "message": "Detailed explanation of the issue",
      "suggested_action": "What to do about it",
      "context": "Any relevant references (dates, documents, regulations)"
    }
  ]
}

Focus on actionable items. Don't generate warnings for things that are fine.`;

      responseFormat = 'warnings';
    } else if (analysisType === 'coverage_triggers') {
      // Two-stage pipeline:
      // 1) Deterministic extraction from existing claim_files.extracted_text (no assumptions)
      // 2) LLM decision constrained to extracted clauses with strict schema + discrete confidence buckets

      const { extractedPolicy, missingDocs: extractionMissingDocs } = extractPolicyFromClaimFiles(files, stateCode);

      // If no declarations/coverage evidence is found, enforce unknown with missing docs (no LLM guessing)
      const hasCoverageEvidence = extractedPolicy.coverages.length > 0;
      if (!hasCoverageEvidence) {
        const enforced: CoverageTriggerResult = {
          coverageTrigger: {
            decision: "unknown",
            confidence: 0,
            rationale: "No declarations/coverage evidence was found in the provided claim documents. Unable to determine coverage trigger without policy/declarations text.",
            missingDocs: extractionMissingDocs.length > 0 ? extractionMissingDocs : ["Declarations page"],
          },
          extractedPolicy,
          notesForUser: [
            "Upload a Declarations page (and/or full policy) so Darwin can extract coverages, limits, and deductibles.",
            "If this is an auto claim, include the declarations for the applicable vehicle and coverage selections.",
            "If this is a property claim, include declarations and relevant coverage sections (Dwelling/Other Structures/Personal Property/Loss of Use).",
          ],
        };

        return new Response(JSON.stringify({
          success: true,
          analysisType,
          result: enforced,
          claimNumber: claim.claim_number,
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
      }

      const claimSnapshot = {
        claim_number: claim.claim_number,
        loss_type: claim.loss_type || null,
        loss_date: claim.loss_date || null,
        status: claim.status || null,
        insurance_company: claim.insurance_company || null,
        deductible: settlement?.deductible ?? claim.deductible ?? null,
        has_denial_letter: files.some((f: any) => (f.document_classification || '').toLowerCase() === 'denial' || (f.file_name || '').toLowerCase().includes('denial')),
        has_estimate: files.some((f: any) => (f.document_classification || '').toLowerCase() === 'estimate' || (f.file_name || '').toLowerCase().includes('estimate')),
        photo_count: photos.length,
      };

      const system = `
You are Darwin, evaluating whether a coverage trigger is supported by the provided policy evidence and claim facts.

Hard rules:
- NO assumed coverage. If the extracted policy evidence is incomplete, use decision "unknown" and list missingDocs needed to become confident.
- You must use discrete confidence buckets ONLY: 0, 0.25, 0.5, 0.75, 1.
- Evidence quotes (if referenced) must be short (<= 25 words) and never fabricate page numbers.
- You are not a lawyer and do not provide legal advice.
`.trim();

      const task = `
You will be given:
1) Deterministically extracted policy evidence (authoritative; do not add new coverages not present).
2) A claim snapshot.

ExtractedPolicy (do NOT modify; treat as fixed evidence):
${JSON.stringify(extractedPolicy, null, 2)}

Claim snapshot:
${JSON.stringify(claimSnapshot, null, 2)}

Task:
Return ONLY valid JSON (no markdown) matching exactly:
{
  "coverageTrigger": {
    "decision": "triggered" | "not_triggered" | "unknown",
    "confidence": 0 | 0.25 | 0.5 | 0.75 | 1,
    "rationale": "short plain English",
    "missingDocs": ["..."]
  },
  "notesForUser": ["..."]
}

Rules:
- If extractedPolicy lacks a deductible OR limit for the most relevant coverage, confidence should not exceed 0.75.
- If extractedPolicy shows coverage exists but the claim facts are insufficient to decide trigger applicability, use "unknown" and explain what fact/doc is missing.
- missingDocs must include specific items that would move "unknown" → confident (e.g., "Declarations page", "Denial letter", "Carrier estimate", "Photos of damage", "Engineer report").
`.trim();

      const { content } = await callLovableChatWithFallback({
        lovableApiKey,
        models: ['openai/gpt-5.2', 'openai/gpt-4.1'],
        messages: [
          { role: 'system', content: system },
          { role: 'user', content: task },
        ],
        temperature: 0.2,
        max_tokens: 1500,
      });

      let parsed: any;
      try {
        parsed = JSON.parse(content);
      } catch (e) {
        // Fail safe: unknown with extraction missing docs
        parsed = {
          coverageTrigger: {
            decision: "unknown",
            confidence: 0.25,
            rationale: "Unable to parse a strict coverage trigger decision. Additional documentation is required to make a defensible determination.",
            missingDocs: extractionMissingDocs.length ? extractionMissingDocs : ["Declarations page"],
          },
          notesForUser: [
            "Provide the declarations page and relevant policy sections to enable a strict, evidence-based coverage trigger determination.",
          ],
        };
      }

      const mergedMissingDocs = Array.from(new Set([
        ...(extractionMissingDocs || []),
        ...((parsed?.coverageTrigger?.missingDocs as string[]) || []),
      ]));

      const finalResult: CoverageTriggerResult = {
        coverageTrigger: {
          decision: parsed?.coverageTrigger?.decision || "unknown",
          confidence: parsed?.coverageTrigger?.confidence ?? 0.25,
          rationale: parsed?.coverageTrigger?.rationale || "Coverage trigger analysis completed.",
          missingDocs: mergedMissingDocs,
        },
        extractedPolicy,
        notesForUser: Array.isArray(parsed?.notesForUser) ? parsed.notesForUser : [],
      };

      return new Response(JSON.stringify({
        success: true,
        analysisType,
        result: finalResult,
        claimNumber: claim.claim_number
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    } else {
      userPrompt = `Provide a brief strategic overview of this claim:

${claimContext}

Give me:
1. One-sentence claim health assessment
2. Top 3 priorities right now
3. Biggest risk or opportunity
4. What a senior PA would focus on`;

      responseFormat = 'overview';
    }

    console.log(`Strategic analysis type: ${analysisType} for claim ${claimId}`);

    // Call AI
    const response = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${lovableApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'google/gemini-2.5-pro',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.3,
        max_tokens: 8000
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('AI API error:', response.status, errorText);
      throw new Error(`AI API error: ${response.status}`);
    }

    const aiData = await response.json();
    const result = aiData.choices?.[0]?.message?.content;

    if (!result) {
      throw new Error('No response from AI');
    }

    // Try to parse as JSON if applicable
    let parsedResult: any = result;
    if (responseFormat !== 'overview') {
      try {
        // Clean up markdown code blocks if present
        let cleanedResult = result;
        if (result.includes('```json')) {
          cleanedResult = result.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
        } else if (result.includes('```')) {
          cleanedResult = result.replace(/```\n?/g, '').trim();
        }
        parsedResult = JSON.parse(cleanedResult);
      } catch (e) {
        console.log('Result is not JSON, returning as text');
        parsedResult = { text: result };
      }
    }

    // Store the insights in the database
    if (analysisType === 'full_strategic_analysis' && typeof parsedResult === 'object') {
      const healthScore = parsedResult.health_score || parsedResult.healthScore || {};
      const warnings = parsedResult.warnings || parsedResult.critical_warnings || [];
      const leveragePoints = parsedResult.leverage_opportunities || parsedResult.leveragePoints || [];
      const coverageTriggers = parsedResult.coverage_trigger_analysis || parsedResult.coverageTriggers || [];
      const evidenceGaps = parsedResult.evidence_assessment?.weak_missing_evidence || [];
      const nextMoves = parsedResult.recommended_next_moves || parsedResult.nextMoves || [];
      const seniorPaOpinion = parsedResult.senior_pa_opinion || parsedResult.seniorPaOpinion || '';

      // Fetch matching carrier playbooks based on claim conditions
      let matchedPlaybooks: any[] = [];
      if (claim.insurance_company) {
        const { data: playbooks } = await supabase
          .from('carrier_playbooks')
          .select('*')
          .eq('is_active', true)
          .ilike('carrier_name', `%${claim.insurance_company.split(' ')[0]}%`)
          .order('priority', { ascending: true })
          .limit(10);
        
        if (playbooks && playbooks.length > 0) {
          // Match playbooks to current claim conditions
          const claimAge = daysOpen || 0;
          const hasSupplementPending = claim.status?.toLowerCase().includes('supplement');
          const checksCount = checks.length;
          
          matchedPlaybooks = playbooks.filter((pb: any) => {
            const trigger = pb.trigger_condition;
            if (!trigger || typeof trigger !== 'object') return true; // General tactics
            
            // Check delay conditions
            if (trigger.delay_days?.gte && claimAge >= trigger.delay_days.gte) return true;
            if (trigger.days_waiting?.gte && claimAge >= trigger.days_waiting.gte) return true;
            
            // Check supplement conditions
            if (trigger.supplement_pending && hasSupplementPending) return true;
            
            // Check denial conditions
            if (trigger.first_denial && hasDenialLetter) return true;
            
            // Check engineer report conditions
            if (trigger.engineer_report_received && hasEngineerReport) return true;
            
            // Check communication gaps
            if (trigger.communication_gap_days?.gte) {
              const lastComm = diary[0]?.communication_date;
              if (lastComm) {
                const daysSinceComm = Math.floor((Date.now() - new Date(lastComm).getTime()) / (1000 * 60 * 60 * 24));
                if (daysSinceComm >= trigger.communication_gap_days.gte) return true;
              }
            }
            
            return false;
          }).slice(0, 5);
        }
      }

      console.log(`Matched ${matchedPlaybooks.length} carrier playbooks for ${claim.insurance_company}`);

      // Upsert strategic insights
      const { error: upsertError } = await supabase
        .from('claim_strategic_insights')
        .upsert({
          claim_id: claimId,
          coverage_strength_score: healthScore.coverage_strength ?? healthScore.coverageStrength ?? null,
          evidence_quality_score: healthScore.evidence_quality ?? healthScore.evidenceQuality ?? null,
          leverage_score: healthScore.leverage_score ?? healthScore.leverageScore ?? null,
          timeline_risk_score: healthScore.timeline_risk ?? healthScore.timelineRisk ?? null,
          overall_health_score: healthScore.overall ?? healthScore.overallHealthScore ?? null,
          warnings: warnings,
          leverage_points: leveragePoints,
          coverage_triggers_detected: coverageTriggers,
          evidence_gaps: evidenceGaps,
          recommended_next_moves: nextMoves,
          matched_playbooks: matchedPlaybooks,
          senior_pa_opinion: typeof seniorPaOpinion === 'string' ? seniorPaOpinion : JSON.stringify(seniorPaOpinion),
          last_analyzed_at: new Date().toISOString(),
          analysis_version: '1.0'
        }, {
          onConflict: 'claim_id'
        });

      if (upsertError) {
        console.error('Error saving insights:', upsertError);
      } else {
        console.log('Strategic insights saved successfully for claim', claimId);
      }

      // Log warnings for tracking
      if (Array.isArray(warnings) && warnings.length > 0) {
        const warningsToInsert = warnings.map((w: any) => ({
          claim_id: claimId,
          warning_type: w.type || 'strategy_alert',
          severity: w.severity || 'medium',
          title: w.title || 'Warning',
          message: w.message || w.description || '',
          suggested_action: w.suggested_action || w.action || '',
          context: w.context ? JSON.stringify(w.context) : null,
          shown_in_context: 'insights_panel'
        }));

        await supabase.from('claim_warnings_log').insert(warningsToInsert);
      }
    }

    return new Response(JSON.stringify({
      success: true,
      analysisType,
      result: parsedResult,
      claimNumber: claim.claim_number
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });

  } catch (error) {
    console.error('Strategic intelligence error:', error);
    return new Response(JSON.stringify({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
});
